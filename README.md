# ACA_Public

[DONE]

- Write first script
- Arranged data treatment to easy cleaned and sequences of words
- Random Forest â€“ Boosted + Grid Searching / XGBoost
- Multilayer Perceptrons
- SVM
- Sentence transformers (BERT multilingual) vs. tokens dataframe // are quite good
- Try if dimensionality reduction could improve performances // not good at all!

[IN PROGRESS]

- Check multilinguality of my transformer model and how could I improve that // I'll keep this for later
- Hard vs. Soft Voting Classifiers

[TODO]

- NN : check RNN

[COMMENTS]

- "distiluse-base-multilingual-cased" seems to lack a bit of dimensionality: Need to do some deeper research on a at-least 768 dimensions multilingual model that is capable of transforming sentences...